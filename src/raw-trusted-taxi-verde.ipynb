{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fe44fad7-7a61-474e-bd92-6e0886dba4b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, regexp_replace, when, lit, max as spark_max, round\n",
    "from pyspark.sql.types import StringType, IntegerType, LongType, DoubleType, DecimalType, TimestampType\n",
    "\n",
    "path = \"/Volumes/workspace/raw-zone/taxi_verde/\"\n",
    "arquivos = dbutils.fs.ls(path)\n",
    "\n",
    "# Dicionário para renomear colunas\n",
    "renomear_colunas = {\n",
    "    \"vendorid\": \"cod_motorista\",\n",
    "    \"lpep_pickup_datetime\": \"dt_hr_inicio\",\n",
    "    \"lpep_dropoff_datetime\": \"dt_hr_fim\",\n",
    "    \"passenger_count\": \"qtd_pessoas\",\n",
    "    \"trip_distance\": \"dist_percorrida\",\n",
    "    \"ratecodeid\": \"cod_taxa\",\n",
    "    \"store_and_fwd_flag\": \"ind_armazenamento\",\n",
    "    \"pulocationid\": \"cod_bairro_origem\",\n",
    "    \"dolocationid\": \"cod_bairro_destino\",\n",
    "    \"payment_type\": \"tipo_pagamento\",\n",
    "    \"trip_type\": \"tipo_viagem\",\n",
    "    \"fare_amount\": \"vlr_taxa_corrida\",\n",
    "    \"extra\": \"vlr_taxa_extra\",\n",
    "    \"mta_tax\": \"vlr_taxa_mta\",\n",
    "    \"tip_amount\": \"vlr_troco\",\n",
    "    \"tolls_amount\": \"vlr_pedagio\",\n",
    "    \"ehail_fee\":\"vlr_gorjeta\",\n",
    "    \"improvement_surcharge\": \"cod_taxa_melhoria\",\n",
    "    \"total_amount\": \"vlr_total\",\n",
    "    \"congestion_surcharge\": \"vlr_taxa_congestao\"\n",
    "}\n",
    "\n",
    "# Dicionário de tipos das colunas\n",
    "tipos_colunas = {\n",
    "    \"cod_motorista\": StringType(),\n",
    "    \"dt_hr_inicio\": TimestampType(),\n",
    "    \"dt_hr_fim\": TimestampType(),\n",
    "    \"qtd_pessoas\": IntegerType(),\n",
    "    \"dist_percorrida\": DecimalType(10, 2),\n",
    "    \"cod_taxa\": IntegerType(),\n",
    "    \"ind_armazenamento\": StringType(),\n",
    "    \"cod_bairro_origem\": StringType(),\n",
    "    \"cod_bairro_destino\": StringType(),\n",
    "    \"tipo_pagamento\": StringType(),\n",
    "    \"tipo_viagem\": IntegerType(),\n",
    "    \"vlr_taxa_corrida\": DecimalType(10, 2),\n",
    "    \"vlr_taxa_extra\": DecimalType(10, 2),\n",
    "    \"vlr_taxa_mta\": DecimalType(10, 2),\n",
    "    \"vlr_troco\": DecimalType(10, 2),\n",
    "    \"vlr_pedagio\": DecimalType(10, 2),\n",
    "    \"vlr_gorjeta\": DecimalType(10, 2),\n",
    "    \"cod_taxa_melhoria\": IntegerType(),\n",
    "    \"vlr_total\": DecimalType(10, 2),\n",
    "    \"vlr_taxa_congestao\": DecimalType(10, 2)\n",
    "}\n",
    "\n",
    "# Garantir que não haverá duplicatas - sempre reprocessa todos os dados\n",
    "spark.sql(\"DROP TABLE IF EXISTS `trusted-zone`.tb_corrida_taxi_verde\")\n",
    "\n",
    "# Lista para armazenar DataFrames processados\n",
    "dfs = []\n",
    "\n",
    "# Processar cada arquivo parquet encontrado\n",
    "for arquivo in arquivos:\n",
    "    if arquivo.name.endswith(\".parquet\"):\n",
    "        # Ler o arquivo\n",
    "        df = spark.read.parquet(arquivo.path)\n",
    "\n",
    "        # Padronizar nomes das colunas para minúsculo\n",
    "        df = df.toDF(*[c.lower() for c in df.columns])\n",
    "\n",
    "        # Renomear colunas usando dicionário\n",
    "        for coluna_antiga, coluna_nova in renomear_colunas.items():\n",
    "            if coluna_antiga in df.columns:\n",
    "                df = df.withColumnRenamed(coluna_antiga, coluna_nova)\n",
    "\n",
    "        # Converter todas as colunas para string para facilitar limpeza\n",
    "        df = df.select([col(c).cast(StringType()).alias(c) for c in df.columns])\n",
    "\n",
    "        # Substituir vírgulas por pontos nos valores decimais\n",
    "        df = df.select([regexp_replace(col(c), \",\", \".\").alias(c) for c in df.columns])\n",
    "\n",
    "        # Converter para os tipos corretos\n",
    "        for coluna in df.columns:\n",
    "            if coluna in tipos_colunas:\n",
    "                tipo_desejado = tipos_colunas[coluna]\n",
    "                \n",
    "                if isinstance(tipo_desejado, (IntegerType, LongType)):\n",
    "                    # Para inteiros: converte via double primeiro para aceitar \"1.0\"\n",
    "                    df = df.withColumn(\n",
    "                        coluna,\n",
    "                        when(col(coluna).rlike(r\"^[0-9]+(\\.[0-9]+)?$\"), \n",
    "                             col(coluna).cast(\"double\").cast(tipo_desejado))\n",
    "                        .otherwise(None)\n",
    "                    )\n",
    "                elif isinstance(tipo_desejado, (DecimalType, DoubleType)):\n",
    "                    # Para decimais: converte e força arredondamento para 2 casas\n",
    "                    df = df.withColumn(\n",
    "                        coluna,\n",
    "                        when(col(coluna).rlike(r\"^[0-9]+(\\.[0-9]+)?$\"), \n",
    "                             round(col(coluna).cast(\"double\"), 2).cast(tipo_desejado))\n",
    "                        .otherwise(None)\n",
    "                    )\n",
    "                elif isinstance(tipo_desejado, TimestampType):\n",
    "                    # Para timestamps\n",
    "                    df = df.withColumn(coluna, col(coluna).cast(TimestampType()))\n",
    "                else:\n",
    "                    # Para strings\n",
    "                    df = df.withColumn(coluna, col(coluna).cast(StringType()))\n",
    "\n",
    "        # Adicionar coluna identificadora da origem\n",
    "        df = df.withColumn(\"origem_taxi\", lit(\"taxi_verde\"))\n",
    "\n",
    "        # Adicionar DataFrame processado à lista\n",
    "        dfs.append(df)\n",
    "\n",
    "# Unir todos os DataFrames se houver arquivos processados\n",
    "if dfs:\n",
    "    df_final = dfs[0]\n",
    "    for df_individual in dfs[1:]:\n",
    "        df_final = df_final.unionByName(df_individual)\n",
    "\n",
    "    # Salvar tabela final com todos os dados\n",
    "    df_final.write.mode(\"overwrite\").option(\"mergeSchema\", \"true\").saveAsTable(\"`trusted-zone`.tb_corrida_taxi_verde\")\n",
    "\n",
    "    display(df_final)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "raw-trusted-taxi-verde",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}